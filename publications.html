<!-- template.html -->
<!-- jinja written by chatgpt -->
<h3> 2024 </h3>
<li><a href="">SELM: Enhancing Speech Emotion Recognition for Out-of-Domain Scenarios</a><br>
    Hazim Bukhari, Soham Deshmukh, Hira Dhamyal, Bhiksha Raj, and Rita Singh<br>
    INTERSPEECH, 2024.</li>
<li><a href="https://arxiv.org/abs/2402.09585">Domain Adaptation for Contrastive Audio-Language Models</a><br>
    Soham Deshmukh, Rita Singh, and Bhiksha Raj<br>
    INTERSPEECH, 2024.</li>
<li><a href="https://arxiv.org/abs/2402.00282">PAM: Prompting Audio-Language Models for Audio Quality Assessment</a><br>
    Soham Deshmukh, Dareen Alharthi, Benjamin Elizalde, Hannes Gamper, Mahmoud Al Ismail, Rita Singh, Bhiksha Raj, and Huaming Wang<br>
    INTERSPEECH, 2024.
            <a href="https://github.com/soham97/PAM">code</a></li>
<li><a href="https://arxiv.org/abs/2310.02298">Prompting Audios Using Acoustic Properties For Emotion Representation</a><br>
    Hira Dhamyal, Benjamin Elizalde, Soham Deshmukh, Huaming Wang, Bhiksha Raj, and Rita Singh<br>
    ICASSP, 2024.
            <a href="https://github.com/soham97/PAM">poster</a></li>
<li><a href="https://arxiv.org/abs/2309.07372">Training Audio Captioning Models without Audio</a><br>
    Soham Deshmukh, Benjamin Elizalde, Dimitra Emmanouilidou, Bhiksha Raj, Rita Singh, and Huaming Wang<br>
    ICASSP, 2024.
            <a href="https://github.com/soham97/PAM">poster</a>, 
            <a href="https://github.com/soham97/PAM">code</a></li>
<li><a href="https://arxiv.org/abs/2309.05767">Natural Language Supervision for General-Purpose Audio Representations</a><br>
    Benjamin Elizalde*, Soham Deshmukh*, and Huaming Wang<br>
    ICASSP, 2024.
            <a href="https://github.com/soham97/PAM">poster</a>, 
            <a href="https://github.com/soham97/PAM">code</a></li>
<h3> 2023 </h3>
<li><a href="https://arxiv.org/abs/2310.04445">LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model</a><br>
    Muhammad Ahmed Shah, Roshan Sharma, Hira Dhamyal, Raphael Olivier, Ankit Shah, Dareen Alharthi, Hazim T Bukhari, Massa Baali, Soham Deshmukh, Michael Kuhlmann, Bhiksha Raj, and Rita Singh<br>
    ArXiv, 2023.</li>
<li><a href="https://arxiv.org/abs/2305.11834">Pengi: An Audio Language Model for Audio Tasks</a><br>
    Soham Deshmukh, Benjamin Elizalde, Rita Singh, and Huaming Wang<br>
    NeurIPS, 2023.
            <a href="https://github.com/soham97/PAM">poster</a>, 
            <a href="https://github.com/microsoft/Pengi">code</a></li>
<li><a href="https://arxiv.org/abs/2209.14275">Audio Retrieval with WavText5K and CLAP Training</a><br>
    Benjamin Elizalde*, Soham Deshmukh*, and Huaming Wang<br>
    INTERSPEECH, 2023.
            <a href="https://github.com/soham97/PAM">poster</a>, 
            <a href="https://github.com/microsoft/Pengi">code</a></li>
<li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2023/03/ICASSP_2023_MultiView_Speech_Emotion_Tompkins.pdf">Multi-View Learning for Speech Emotion Recognition</a><br>
    Daniel Tompkins, Dimitra Emmanouilidou, Soham Deshmukh, and Benjamin Elizalde<br>
    ICASSP, 2023.</li>
<li><a href="https://arxiv.org/abs/2206.04769">CLAP: Learning Audio Concepts From Natural Language Supervision</a><br>
    Benjamin Elizalde, Soham Deshmukh, Mahmoud Al Ismail, and Huaming Wang<br>
    ICASSP, 2023.</li>
<h3> 2021 </h3>
<li><a href="https://arxiv.org/abs/2106.06858">Improving weakly supervised sound event detection with self-supervised auxiliary tasks</a><br>
    Soham Deshmukh, Bhiksha Raj, and Rita Singh<br>
    INTERSPEECH, 2021.
            <a href="https://github.com/soham97/MTL_Weakly_labelled_audio_data">code</a>, 
            <a href="https://soham97.github.io/assets/pdf/INTERSPEECH_21_slides.pdf">slides</a></li>
<li><a href="https://arxiv.org/abs/2010.10707">Detection of Covid-19 Through the Analysis of Vocal Fold Oscillations</a><br>
    Mahmoud Al Ismail, Soham Deshmukh, and Rita Singh<br>
    ICASSP, 2021.</li>
<li><a href="https://arxiv.org/abs/2010.16318">Interpreting Glottal Flow Dynamics for Detecting Covid-19 From Voice</a><br>
    Soham Deshmukh, Mahmoud Al Ismail, and Rita Singh<br>
    ICASSP, 2021.</li>
<h3> 2020 </h3>
<li><a href="https://arxiv.org/abs/2008.07085">Multi-Task Learning for Interpretable Weakly Labelled Sound Event Detection</a><br>
    Soham Deshmukh, Bhiksha Raj, and Rita Singh<br>
    ArXiv, 2020.</li>
<h3> 2019 and before </h3>
<li><a href="">Temporal and Stochastic Modelling of Attacker Behaviour</a><br>
    Rahul Rade, Soham Deshmukh, Ruturaj Nene, Amey S. Wadekar, and Ajay Unny<br>
    ICIIT, 2019.</li>
<li><a href="">Tackling Toxic Online Communication with Recurrent Capsule Networks</a><br>
    Soham Deshmukh, and Rahul Rade<br>
    CICT, 2018.</li>
