<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Voice analytics for healthcare | Soham Deshmukh</title> <meta name="author" content="Soham Deshmukh"> <meta name="description" content="Detecting upper respiratory tract illness through patients voice"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, soham deshmukh, microsoft, cmu, audio, speech"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9D%84%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://soham97.github.io/projects/health/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Soham </span>Deshmukh</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">talks &amp; teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Voice analytics for healthcare</h1> <p class="post-description">Detecting upper respiratory tract illness through patients voice</p> </header> <article> <p>Voice analytics for healthcare is an evolving research direction where the aim is to process the continuous acoustic signal and generate insights about the patient’s conditions. Traditionally, speech technology in the healthcare industry has been utilised for transcribing patient notes for doctors, detect patient emotion, and improving the doctor-patient experience. There is also an emerging direction of speech technology for healthcare where the aim is to assist doctors in medical diagnosis. The assistance can be in the form of diagnosis prediction or symptom detection.</p> <p>The ability of speech technology to predict medical conditions is continuously being improved over the past decade in different directions. The recent work by:</p> <ul> <li> <a href="https://web.eecs.umich.edu/~emilykmp/" rel="external nofollow noopener" target="_blank">Emily Provost</a> (<a href="https://web.eecs.umich.edu/~emilykmp/chai/index.html" rel="external nofollow noopener" target="_blank">CHAI lab</a>) in assistive technology for bipolar disorder, aphasia, Huntington disease, suicide risk</li> <li> <a href="https://engineering.jhu.edu/ece/faculty/najim-dehak/" rel="external nofollow noopener" target="_blank">Najim Dehak</a> and <a href="https://pages.jh.edu/lmorove1/index.html" rel="external nofollow noopener" target="_blank">Laureano Moro-Velázquez</a> in early Parkinson’s disease detection</li> <li> <a href="https://www.ee.ucla.edu/abeer-alwan/" rel="external nofollow noopener" target="_blank">Abeer Alwan</a> (<a href="http://www.seas.ucla.edu/spapl/index.html" rel="external nofollow noopener" target="_blank">SPAPL lab</a>) in analysis of disfluency in children’s speech</li> </ul> <p>The COVID-19 pandemic starting in 2019 has resulted in more than 100 million infections, and more than 2 million casualties. The global crisis spans over 200 countries. One of the ways to slow the exponential growth down is early detection of COVID-19 infection in a patient followed by quick isolation. The traditional testing methods are expensive, takes 3-5 days to get results and are insufficient in number. This motivates transfering speech technology for the detection of symtoms of such disease.</p> <h4 id="-can-we-non-invasively-characterize-and-detect-covid-19-from-voice-"><i> Can we non-invasively characterize and detect COVID-19 from voice? </i></h4> <p>Trying to answer this question has the potential to enable rapid and scalable testing, reducing its prevalence and saving lives.</p> <p>Voiced sounds are produced through the process of phonation, where the movement of vocal folds are self-sustained through the interaction of physical and aerodynamic forces across the glottis. The actual movements are governed by various biomechanical properties of the vocal fold such as elasticity, resistance, Young’s modulus, viscosity etc.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/vocalfold.png" alt="" title="example image"> </div> </div> <div class="caption"> Laryngoscopic view of the vocal folds </div> <p>This vocal fold motion and voice production can be simulated by physics models with assumptions. This discrepany surfaces up in glottal flow waveform generated by a physical model of healthy person (1d asymmetrical body mass model) vs actual glottal waveform obtained. So by capturing the vocal fold oscillation impairment as discrepancy surfacing in the form of differences between glottal flow waveform obtained from inverse filtering and glottal flow waveform estimated from 1d asymmetrical body mass model, can provide the required insight about upper respiratory track diseases.</p> <h4 id="adles-adjoint-least-square-estimation-method">ADLES (adjoint least square estimation method)</h4> \[\min \int_{0}^{T} (u_0(t) - u_0^m(t))^2 dt\] \[\min \int_{0}^{T} (\tilde{c}d(2x_0 + x_l(t) + x_r(t)) - \frac{A(0)}{\rho c}\mathcal{F}^{-1}(p_m(t)))^2\] \[\mathrm{s.t.}\quad \ddot{x}_r + \beta (1 + x_r^2)\dot{x}_r + x_r - \frac{\Delta}{2}x_r = \alpha (\dot{x}_r + \dot{x}_l)\] \[\ddot{x}_l + \beta (1 + x_l^2)\dot{x}_l + x_l + \frac{\Delta}{2}x_l = \alpha (\dot{x}_r + \dot{x}_l)\] \[x_r(0) = C_r, x_l(0) = C_l\] \[\dot{x}_r(0) = 0, \dot{x}_l(0) = 0\] <p>We use ADLES algorithm to iteratively estimate the model parameters \(\alpha\), \(\beta\), \(\Delta\). This is achieved by minimizing the error between the glottal flow waveform obtained by inverse filtering, and the vocal fold oscillations predicted by the model as its parameter space is sampled.</p> <p>The phasor plots obtained are shown below:</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/male_negative.png" alt="" title="example image"> </div> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/male_positive.png" alt="" title="example image"> </div> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/female_negative_3.png" alt="" title="example image"> </div> <div class="col-sm mt-3 mt-md-0"> <img class="img-fluid rounded z-depth-1" src="/assets/img/female_positive.png" alt="" title="example image"> </div> </div> <div class="caption"> The second and fourth plots are phase space trajectories for male and female symptomatic COVID-19 patients for the vowel /i/. While the first and third plots are phase space trajectories for male and female healthy patients for the vowel /i/. In each plot, the left panel corresponds to left vocal fold displacement (x-axis) vs. left vocal fold velocity (y-axis) and right panel corresponds to right vocal fold displacement (x-axis) vs. right vocal fold velocity (y-axis) </div> <p>This approach provides a physics motivated approach to distinguish upper respiratory tract illness symtomatic patients.</p> <p>There has been recent development in COVID-19 detection with <a href="https://dicova2021.github.io/" rel="external nofollow noopener" target="_blank">DiCOVA Challenge</a> at INTERSPEECH 2021. This has lead to deep learning based methods being introduced as well.</p> <h2 id="references">References</h2> <p>[1] M. Al Ismail, S. Deshmukh and R. Singh, “Detection of Covid-19 Through the Analysis of Vocal Fold Oscillations,” ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021, pp. 1035-1039, doi: 10.1109/ICASSP39728.2021.9414201</p> <p>[2] S. Deshmukh, M. Al Ismail and R. Singh, “Interpreting Glottal Flow Dynamics for Detecting Covid-19 From Voice,” ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2021, pp. 1055-1059, doi: 10.1109/ICASSP39728.2021.9414530</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Soham Deshmukh. Last updated: June 10, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-127734545-1"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-127734545-1");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>